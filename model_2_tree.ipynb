{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화를 해서 dt에 넣어보기 -> 모든 데이터를 0~1 사이의 값이 될 수 있또록\n",
    "lead_time, avg_price_per_room -> cate ->  num으로 바꾸기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Booking_ID', 'no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
       "       'no_of_week_nights', 'type_of_meal_plan', 'required_car_parking_space',\n",
       "       'room_type_reserved', 'lead_time', 'arrival_year', 'arrival_month',\n",
       "       'arrival_date', 'market_segment_type', 'repeated_guest',\n",
       "       'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
       "       'avg_price_per_room', 'no_of_special_requests', 'booking_status',\n",
       "       'meal_type_1', 'meal_type_2', 'meal_type_3', 'meal_type_4',\n",
       "       'room_type_1', 'room_type_2', 'room_type_3', 'room_type_4',\n",
       "       'room_type_5', 'room_type_6', 'room_type_7', 'Corporate',\n",
       "       'Complementary', 'Online', 'Offline', 'Aviation',\n",
       "       'lead_time_under_iqr_1', 'lead_time_under_iqr_2',\n",
       "       'lead_time_under_iqr_3', 'lead_time_under_iqr_4', 'price_under_iqr_1',\n",
       "       'price_under_iqr_2', 'price_under_iqr_3', 'price_under_iqr_4',\n",
       "       'lead_time_norm', 'price_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('final_train.csv')\n",
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_names]\n",
    "y = train[\"booking_status\"]\n",
    "smote = SMOTEENN(random_state = 0)\n",
    "X_train_over, y_train_over = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.88779528 0.87598425 0.86614173 0.85629921 0.87992126 0.85826772\n",
      " 0.87598425 0.88385827 0.89370079 0.88188976 0.86023622 0.86614173\n",
      " 0.88385827 0.87598425 0.89173228 0.90551181 0.84055118 0.87401575\n",
      " 0.86811024 0.88582677 0.86023622 0.86417323 0.88385827 0.88582677\n",
      " 0.87007874 0.8503937  0.89173228 0.87204724 0.88976378 0.87401575\n",
      " 0.87795276 0.87992126 0.85629921 0.86220472 0.87204724 0.9015748\n",
      " 0.88385827 0.85433071 0.87795276 0.86811024 0.88385827 0.88385827\n",
      " 0.86193294 0.89940828 0.86193294 0.87179487 0.85601578 0.85996055\n",
      " 0.85404339 0.8816568 ]\n",
      "Average CV Score:  0.8740530214788241\n",
      "Number of CV Scores used in Average:  50\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "feature_names = ['no_of_adults', 'no_of_children',\n",
    "'no_of_weekend_nights',\n",
    "                 'no_of_week_nights', 'required_car_parking_space',\n",
    "                 'lead_time', 'arrival_year', 'arrival_month',\n",
    "                 'arrival_date', 'repeated_guest',\n",
    "                 'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
    "                 'avg_price_per_room', 'no_of_special_requests',\n",
    "                 'meal_type_1', 'meal_type_2', 'meal_type_3', 'meal_type_4',\n",
    "                 'room_type_1', 'room_type_2', 'room_type_3', 'room_type_4',\n",
    "                 'room_type_5', 'room_type_6', 'room_type_7', 'Corporate',\n",
    "                 'Complementary', 'Online', 'Offline', 'Aviation']\n",
    "'''\n",
    "\n",
    "train = pd.read_csv('final_train.csv')\n",
    "train['lead_12'] = train['lead_time_under_iqr_1'] + train['lead_time_under_iqr_2']\n",
    "train['lead_34'] = train['lead_time_under_iqr_3'] + train['lead_time_under_iqr_4']\n",
    "train['price_12'] = train['price_under_iqr_1'] + train['price_under_iqr_2']\n",
    "train['price_34'] = train['price_under_iqr_3'] + train['price_under_iqr_4']\n",
    "\n",
    "feature_names = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
    "       'no_of_week_nights', 'required_car_parking_space',\n",
    "       'arrival_year', 'arrival_month',\n",
    "       'arrival_date', 'repeated_guest',\n",
    "       'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
    "       'no_of_special_requests', \n",
    "       'meal_type_1', 'meal_type_2', 'meal_type_3', 'meal_type_4',\n",
    "       'room_type_1', 'room_type_2', 'room_type_3', 'room_type_4',\n",
    "       'room_type_5', 'room_type_6', 'room_type_7', 'Corporate',\n",
    "       'Complementary', 'Online', 'Offline', 'Aviation',\n",
    "       'lead_time_norm', 'price_norm', 'lead_12', 'lead_34', 'price_12', 'price_34']\n",
    "\n",
    "# 87 프로 피쳐\n",
    "# train = pd.read_csv('onehot_sample.csv')\n",
    "\n",
    "# feature_names = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
    "#                  'no_of_week_nights', 'required_car_parking_space',\n",
    "#                  'lead_time', 'arrival_year', 'arrival_month',\n",
    "#                  'arrival_date', 'repeated_guest',\n",
    "#                  'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
    "#                  'avg_price_per_room', 'no_of_special_requests',\n",
    "#                  'meal_type_1', 'meal_type_2', 'meal_type_3', 'meal_type_4',\n",
    "#                  'room_type_1', 'room_type_2', 'room_type_3', 'room_type_4',\n",
    "#                  'room_type_5', 'room_type_6', 'room_type_7', 'Corporate',\n",
    "#                  'Complementary', 'Online', 'Offline', 'Aviation']\n",
    "\n",
    "X = train[feature_names]\n",
    "y = train[\"booking_status\"]\n",
    "smote = SMOTE(random_state = 42)\n",
    "# Decision Tree 학습/예측/평가\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Decision Tree 학습/예측/평가\n",
    "dt_model = DecisionTreeClassifier(max_depth = 15, min_samples_leaf = 2, min_samples_split = 2, criterion=\"gini\", max_features = 25)\n",
    "scores = cross_val_score(dt_model, X, y, cv = 50)\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 256 candidates, totalling 2560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "640 fits failed out of a total of 2560.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.85612285 0.85811782 0.85717238 0.85722455 0.85979739 0.85754003\n",
      " 0.85711995 0.85669956 0.8583273  0.86021824 0.85617493 0.85822297\n",
      " 0.85512522 0.85617531 0.85438971 0.8560698  0.85911514 0.85880084\n",
      " 0.85743521 0.85811796 0.85874793 0.85916733 0.85696247 0.85974531\n",
      " 0.86027035 0.86026999 0.85974545 0.85701471 0.85827491 0.85916774\n",
      " 0.85927259 0.85806505 0.85680408 0.85318255 0.85643783 0.85486171\n",
      " 0.85733064 0.85696274 0.85853788 0.85832779 0.85580753 0.85522952\n",
      " 0.85880029 0.85848508 0.85622761 0.85580673 0.85648978 0.85643775\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.8643135  0.86410386\n",
      " 0.86536381 0.86641451 0.86630906 0.86457614 0.86657158 0.86478578\n",
      " 0.86399885 0.86126839 0.86368458 0.86384126 0.86573146 0.86321084\n",
      " 0.86473442 0.8656275  0.86840929 0.86835696 0.86746441 0.86714967\n",
      " 0.86594177 0.86652005 0.86772665 0.86762252 0.86615163 0.8670446\n",
      " 0.86562692 0.86699188 0.86447129 0.86573163 0.86594174 0.86515395\n",
      " 0.86730706 0.86636218 0.8644717  0.86672972 0.86515417 0.86268602\n",
      " 0.86762236 0.86499647 0.86525883 0.86657177 0.86447148 0.86525858\n",
      " 0.86399821 0.86468151 0.86384151 0.86699141        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.86867283 0.8650491  0.8691984  0.86284454\n",
      " 0.86373732 0.86489206 0.86357901 0.86294903 0.86231831 0.86331649\n",
      " 0.86195067 0.86531259 0.86179305 0.86263341 0.8644709  0.86174174\n",
      " 0.86951339 0.86898815 0.86546949 0.86720153 0.86273903 0.86457705\n",
      " 0.86210837 0.86441948 0.86541703 0.86195158 0.86258158 0.86483971\n",
      " 0.86636097 0.86226571 0.86116269 0.86452475 0.8674646  0.86883028\n",
      " 0.86672958 0.86594196 0.86310627 0.86552229 0.86205579 0.86520697\n",
      " 0.86473384 0.86342161 0.86231859 0.8646811  0.86231837 0.86510157\n",
      " 0.86221313 0.86331583        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.8612688  0.86142562 0.85985032 0.86352707 0.86305438 0.85790713\n",
      " 0.85874881 0.8587481  0.85979747 0.85801294 0.85885314 0.85922117\n",
      " 0.85932503 0.85869511 0.86111044 0.85874724 0.86153102 0.86126913\n",
      " 0.8576454  0.86084847 0.85927416 0.85985018 0.8582236  0.85880089\n",
      " 0.85948323 0.85869577 0.85964101 0.85943109 0.86179313 0.85817034\n",
      " 0.85811738 0.85859051 0.86457741 0.85985115 0.85874818 0.85670014\n",
      " 0.85869538 0.86147886 0.85979863 0.85880009 0.85559728 0.85759363\n",
      " 0.85475782 0.85654304 0.85864289 0.85885212 0.85832779 0.85785524\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=DecisionTreeClassifier(max_depth=15, max_features=30,\n",
       "                                              min_samples_leaf=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [8, 10, 15, 20],\n",
       "                         'max_features': [25, 30, 25, 40],\n",
       "                         'min_samples_leaf': [2, 4, 6, 8],\n",
       "                         'min_samples_split': [2, 4, 6, 8]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dt_graph(dt_classifier):\n",
    "    fig = plt.figure(figsize=(25, 20))\n",
    "    _ = dt_model.plot_tree(dt_classifier,\n",
    "                       feature_names=X.columns,\n",
    "                       class_names=['No Disease', \"Disease\"],\n",
    "                       filled=True)\n",
    "\n",
    "\n",
    "def evaluate_model(dt_classifier):\n",
    "    print(\"Train Accuracy :\", accuracy_score(\n",
    "        y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Test Accuracy :\", accuracy_score(\n",
    "        y_test, dt_classifier.predict(X_test)))\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [8, 10, 15, 20], \n",
    "    'min_samples_leaf' : [2, 4, 6, 8], \n",
    "    'min_samples_split' : [2, 4, 6, 8],\n",
    "    'max_features' : [25, 30, 25, 40]\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'max_features' : [5, 10, 15, 20, 25, 30, 35]\n",
    "# }\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=dt_model,\n",
    "                           param_grid=params,\n",
    "                           cv=10, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.152400</td>\n",
       "      <td>0.029406</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 30, 'min_sam...</td>\n",
       "      <td>0.849344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864567</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>0.873424</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.882878</td>\n",
       "      <td>0.873424</td>\n",
       "      <td>0.869513</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.126103</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 25, 'min_sam...</td>\n",
       "      <td>0.845144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.870273</td>\n",
       "      <td>0.879202</td>\n",
       "      <td>0.872899</td>\n",
       "      <td>0.870273</td>\n",
       "      <td>0.865021</td>\n",
       "      <td>0.871849</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.117539</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 30, 'min_sam...</td>\n",
       "      <td>0.844094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865092</td>\n",
       "      <td>0.855567</td>\n",
       "      <td>0.870273</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>0.873424</td>\n",
       "      <td>0.878151</td>\n",
       "      <td>0.870798</td>\n",
       "      <td>0.868988</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.125506</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 25, 'min_sam...</td>\n",
       "      <td>0.844619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871916</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.871849</td>\n",
       "      <td>0.876050</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.876576</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.868830</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.110737</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 25, 'min_sam...</td>\n",
       "      <td>0.846719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874541</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.863971</td>\n",
       "      <td>0.868697</td>\n",
       "      <td>0.878151</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.872899</td>\n",
       "      <td>0.868673</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "144       0.152400      0.029406         0.004989        0.002522   \n",
       "130       0.126103      0.033440         0.005540        0.004203   \n",
       "145       0.117539      0.010522         0.003591        0.000661   \n",
       "161       0.125506      0.030567         0.004484        0.001048   \n",
       "128       0.110737      0.022340         0.004388        0.000798   \n",
       "\n",
       "    param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "144              15                 30                      2   \n",
       "130              15                 25                      2   \n",
       "145              15                 30                      2   \n",
       "161              15                 25                      2   \n",
       "128              15                 25                      2   \n",
       "\n",
       "    param_min_samples_split  \\\n",
       "144                       2   \n",
       "130                       6   \n",
       "145                       4   \n",
       "161                       4   \n",
       "128                       2   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "144  {'max_depth': 15, 'max_features': 30, 'min_sam...           0.849344   \n",
       "130  {'max_depth': 15, 'max_features': 25, 'min_sam...           0.845144   \n",
       "145  {'max_depth': 15, 'max_features': 30, 'min_sam...           0.844094   \n",
       "161  {'max_depth': 15, 'max_features': 25, 'min_sam...           0.844619   \n",
       "128  {'max_depth': 15, 'max_features': 25, 'min_sam...           0.846719   \n",
       "\n",
       "     ...  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "144  ...           0.864567           0.858718           0.876050   \n",
       "130  ...           0.862467           0.870273           0.879202   \n",
       "145  ...           0.865092           0.855567           0.870273   \n",
       "161  ...           0.871916           0.856618           0.871849   \n",
       "128  ...           0.874541           0.867647           0.863971   \n",
       "\n",
       "     split6_test_score  split7_test_score  split8_test_score  \\\n",
       "144           0.873424           0.865546           0.882878   \n",
       "130           0.872899           0.870273           0.865021   \n",
       "145           0.876050           0.873424           0.878151   \n",
       "161           0.876050           0.867647           0.876576   \n",
       "128           0.868697           0.878151           0.866071   \n",
       "\n",
       "     split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "144           0.873424         0.869513        0.010067                1  \n",
       "130           0.871849         0.869198        0.010974                2  \n",
       "145           0.870798         0.868988        0.011059                3  \n",
       "161           0.868172         0.868830        0.010085                4  \n",
       "128           0.872899         0.868673        0.008433                5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv = 10, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
    "             param_grid={'min_samples_split': [5, 10, 20, 50, 100]},\n",
    "             scoring='accuracy', verbose=1)\n",
    "\n",
    "score_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# score_df.to_csv('dt_model_grid_search.csv')\n",
    "score_df.nlargest(5, \"mean_test_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=15, max_features=25, min_samples_leaf=2,\n",
       "                       min_samples_split=4)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt_model.fit(X_train_over, y_train_over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Train Accuracy : 0.9133585381222432\n",
      "Train Confusion Matrix:\n",
      "[[11975   860]\n",
      " [  790  5419]]\n",
      "--------------------------------------------------\n",
      "Test Accuracy : 0.8649968494013862\n",
      "Test Confusion Matrix:\n",
      "[[3807  472]\n",
      " [ 385 1684]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt_model.predict(X_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "evaluate_model(dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "real_test = pd.read_csv('test.csv')\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# fit_transform은 train에만 사용하고 test에는 학습된 인코더에 fit만 해야한다\n",
    "train_cat = ohe.fit_transform(real_test[['type_of_meal_plan']])\n",
    "train_cat = pd.DataFrame(train_cat)\n",
    "real_test['meal_type_1'] = train_cat.loc[:, 0]\n",
    "real_test['meal_type_2'] = train_cat.loc[:, 1]\n",
    "real_test['meal_type_3'] = train_cat.loc[:, 2]\n",
    "real_test['meal_type_4'] = train_cat.loc[:, 3]\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# fit_transform은 train에만 사용하고 test에는 학습된 인코더에 fit만 해야한다\n",
    "train_cat = ohe.fit_transform(real_test[['room_type_reserved']])\n",
    "train_cat = pd.DataFrame(train_cat)\n",
    "real_test['Room_Type_1'] = train_cat.loc[:, 0]\n",
    "real_test['Room_Type_2'] = train_cat.loc[:, 1]\n",
    "real_test['Room_Type_3'] = train_cat.loc[:, 2]\n",
    "real_test['Room_Type_4'] = train_cat.loc[:, 3]\n",
    "real_test['Room_Type_5'] = train_cat.loc[:, 4]\n",
    "real_test['Room_Type_6'] = train_cat.loc[:, 5]\n",
    "real_test['Room_Type_7'] = train_cat.loc[:, 6]\n",
    "\n",
    "train_cat = ohe.fit_transform(real_test[['market_segment_type']])\n",
    "train_cat = pd.DataFrame(train_cat)\n",
    "real_test['Corporate'] = train_cat.loc[:, 0]\n",
    "real_test['Complementary'] = train_cat.loc[:, 1]\n",
    "real_test['Online'] = train_cat.loc[:, 2]\n",
    "real_test['Offline'] = train_cat.loc[:, 3]\n",
    "real_test['Aviation'] = train_cat.loc[:, 4]\n",
    "\n",
    "lead_time_norm = (real_test['lead_time'] - real_test['lead_time'].mean())/real_test['lead_time'].std()\n",
    "price_norm = (real_test['avg_price_per_room'] - real_test['avg_price_per_room'].mean())/real_test['avg_price_per_room'].std()\n",
    "\n",
    "real_test['lead_time_norm'] = lead_time_norm\n",
    "real_test['price_norm'] = price_norm\n",
    "\n",
    "real_test.to_csv('onehot_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Booking_ID', 'no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
       "       'no_of_week_nights', 'type_of_meal_plan', 'required_car_parking_space',\n",
       "       'room_type_reserved', 'lead_time', 'arrival_year', 'arrival_month',\n",
       "       'arrival_date', 'market_segment_type', 'repeated_guest',\n",
       "       'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
       "       'avg_price_per_room', 'no_of_special_requests', 'meal_type_1',\n",
       "       'meal_type_2', 'meal_type_3', 'meal_type_4', 'Room_Type_1',\n",
       "       'Room_Type_2', 'Room_Type_3', 'Room_Type_4', 'Room_Type_5',\n",
       "       'Room_Type_6', 'Room_Type_7', 'Corporate', 'Complementary', 'Online',\n",
       "       'Offline', 'Aviation', 'lead_time_norm', 'price_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Room_Type_1\n",
      "- Room_Type_2\n",
      "- Room_Type_3\n",
      "- Room_Type_4\n",
      "- Room_Type_5\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- room_type_1\n",
      "- room_type_2\n",
      "- room_type_3\n",
      "- room_type_4\n",
      "- room_type_5\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "real_test = pd.read_csv('onehot_test.csv')\n",
    "\n",
    "feature_names = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
    "       'no_of_week_nights', 'required_car_parking_space',\n",
    "       'arrival_year', 'arrival_month',\n",
    "       'arrival_date', 'repeated_guest',\n",
    "       'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
    "       'no_of_special_requests', \n",
    "       'meal_type_1', 'meal_type_2', 'meal_type_3', 'meal_type_4',\n",
    "       'Room_Type_1',\n",
    "       'Room_Type_2', 'Room_Type_3', 'Room_Type_4', 'Room_Type_5',\n",
    "       'Room_Type_6', 'Room_Type_7', 'Corporate',\n",
    "       'Complementary', 'Online', 'Offline', 'Aviation',\n",
    "       'lead_time_norm', 'price_norm']\n",
    "\n",
    "test = real_test[feature_names]\n",
    "y_pred = dt_model.predict(test)\n",
    "\n",
    "sample = pd.DataFrame()\n",
    "sample['Booking_ID'] = real_test['Booking_ID']\n",
    "sample['booking_status'] = y_pred\n",
    "sample.to_csv('sample.csv', index=False)\n",
    "# real_test.keys()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
